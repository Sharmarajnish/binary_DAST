"""
Vulnerability Scorer Module
Risk assessment and prioritization for DAST findings.
"""

from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class ScoringResult:
    """Result of vulnerability scoring."""
    base_score: float
    severity_label: str
    exploitability: str
    impact: str
    automotive_impact: str
    priority: int
    notes: List[str]


class VulnerabilityScorer:
    """
    Risk assessment for DAST vulnerabilities.
    
    Uses a CVSS-like scoring system adapted for automotive context,
    with additional factors for safety-critical systems.
    """
    
    # Severity thresholds
    SEVERITY_THRESHOLDS = {
        'critical': 9.0,
        'high': 7.0,
        'medium': 4.0,
        'low': 0.1,
        'info': 0.0,
    }
    
    # Base scores by vulnerability type
    TYPE_SCORES: Dict[str, float] = {
        'crash': 7.0,
        'buffer_overflow': 8.5,
        'use_after_free': 9.0,
        'format_string': 7.5,
        'integer_overflow': 6.5,
        'command_injection': 9.5,
        'null_pointer_deref': 5.0,
        'dangerous_function': 6.0,
        'hang': 4.0,
        'security_bypass': 8.0,
        'unauthorized_access': 7.5,
        'can_injection': 8.0,
        'protocol_violation': 5.5,
        'simulated_finding': 3.0,
    }
    
    # CWE severity modifiers
    CWE_MODIFIERS: Dict[str, float] = {
        'CWE-787': 1.2,   # Out-of-bounds Write - very dangerous
        'CWE-416': 1.3,   # Use After Free - often exploitable
        'CWE-78': 1.4,    # OS Command Injection - critical
        'CWE-77': 1.3,    # Command Injection
        'CWE-120': 1.1,   # Buffer overflow
        'CWE-134': 1.1,   # Format string
        'CWE-190': 0.9,   # Integer overflow - often needs chaining
        'CWE-476': 0.7,   # NULL pointer - usually DoS only
        'CWE-835': 0.6,   # Infinite loop - DoS
    }
    
    # Exploitability factors
    EXPLOITABILITY_SCORES: Dict[str, float] = {
        'high': 1.0,
        'medium': 0.75,
        'low': 0.5,
        'unknown': 0.6,
    }
    
    # Automotive safety impact levels (ISO 26262)
    AUTOMOTIVE_IMPACTS: Dict[str, Dict[str, Any]] = {
        'ASIL-D': {
            'description': 'Highest risk - life-threatening hazards',
            'multiplier': 1.5,
            'cwe_patterns': ['CWE-787', 'CWE-416', 'CWE-78', 'CWE-77']
        },
        'ASIL-C': {
            'description': 'Severe injury possible',
            'multiplier': 1.3,
            'cwe_patterns': ['CWE-120', 'CWE-119', 'CWE-134']
        },
        'ASIL-B': {
            'description': 'Moderate injury risk',
            'multiplier': 1.1,
            'cwe_patterns': ['CWE-190', 'CWE-362', 'CWE-476']
        },
        'ASIL-A': {
            'description': 'Light injury possible',
            'multiplier': 1.0,
            'cwe_patterns': ['CWE-835', 'CWE-674', 'CWE-369']
        },
        'QM': {
            'description': 'Quality Management - no safety impact',
            'multiplier': 0.8,
            'cwe_patterns': []
        }
    }
    
    def __init__(self, automotive_context: bool = True):
        """
        Initialize vulnerability scorer.
        
        Args:
            automotive_context: Apply automotive-specific scoring adjustments
        """
        self.automotive_context = automotive_context
    
    def calculate_score(self, vuln: Dict[str, Any]) -> ScoringResult:
        """
        Calculate risk score for a vulnerability.
        
        Args:
            vuln: Vulnerability dictionary
            
        Returns:
            ScoringResult with calculated scores
        """
        notes = []
        
        # Get base score from type
        vuln_type = vuln.get('type', 'unknown')
        base_score = self.TYPE_SCORES.get(vuln_type, 5.0)
        notes.append(f"Base score from type '{vuln_type}': {base_score}")
        
        # Apply CWE modifier
        cwe_id = vuln.get('cwe_id', '')
        cwe_modifier = self.CWE_MODIFIERS.get(cwe_id, 1.0)
        if cwe_modifier != 1.0:
            notes.append(f"CWE modifier for {cwe_id}: {cwe_modifier}")
        base_score *= cwe_modifier
        
        # Apply exploitability factor
        exploitability = vuln.get('exploitability', 'unknown')
        exploit_factor = self.EXPLOITABILITY_SCORES.get(exploitability, 0.6)
        notes.append(f"Exploitability '{exploitability}': {exploit_factor}")
        
        # Adjust score based on exploitability
        # High exploitability increases score, low decreases
        if exploit_factor < 0.7:
            base_score *= 0.9
        elif exploit_factor > 0.9:
            base_score *= 1.1
        
        # Apply automotive context
        automotive_impact = 'N/A'
        if self.automotive_context:
            automotive_impact = self._assess_automotive_impact(vuln)
            asil_info = self.AUTOMOTIVE_IMPACTS.get(automotive_impact, {})
            multiplier = asil_info.get('multiplier', 1.0)
            
            if multiplier != 1.0:
                notes.append(f"Automotive impact ({automotive_impact}): {multiplier}x")
                base_score *= multiplier
        
        # Cap at 10.0
        base_score = min(10.0, max(0.0, base_score))
        
        # Determine severity label
        severity = self._score_to_severity(base_score)
        
        # Calculate priority (1-5, where 1 is highest)
        priority = self._calculate_priority(base_score, exploitability, automotive_impact)
        
        return ScoringResult(
            base_score=round(base_score, 1),
            severity_label=severity,
            exploitability=exploitability,
            impact=self._get_impact_description(vuln_type),
            automotive_impact=automotive_impact,
            priority=priority,
            notes=notes
        )
    
    def _score_to_severity(self, score: float) -> str:
        """Convert numeric score to severity label."""
        
        if score >= self.SEVERITY_THRESHOLDS['critical']:
            return 'critical'
        elif score >= self.SEVERITY_THRESHOLDS['high']:
            return 'high'
        elif score >= self.SEVERITY_THRESHOLDS['medium']:
            return 'medium'
        elif score >= self.SEVERITY_THRESHOLDS['low']:
            return 'low'
        else:
            return 'info'
    
    def _assess_automotive_impact(self, vuln: Dict[str, Any]) -> str:
        """Assess automotive safety impact level (ASIL)."""
        
        cwe_id = vuln.get('cwe_id', '')
        
        for asil, info in self.AUTOMOTIVE_IMPACTS.items():
            if cwe_id in info['cwe_patterns']:
                return asil
        
        # Default based on severity
        severity = vuln.get('severity', 'medium')
        if severity == 'critical':
            return 'ASIL-C'
        elif severity == 'high':
            return 'ASIL-B'
        elif severity == 'medium':
            return 'ASIL-A'
        else:
            return 'QM'
    
    def _get_impact_description(self, vuln_type: str) -> str:
        """Get impact description for vulnerability type."""
        
        impacts = {
            'crash': 'Denial of service, potential code execution',
            'buffer_overflow': 'Memory corruption, potential code execution',
            'use_after_free': 'Memory corruption, likely code execution',
            'format_string': 'Information disclosure, potential code execution',
            'integer_overflow': 'Memory corruption, denial of service',
            'command_injection': 'Arbitrary command execution',
            'null_pointer_deref': 'Denial of service',
            'dangerous_function': 'Potential memory corruption',
            'hang': 'Denial of service',
            'security_bypass': 'Unauthorized access',
            'unauthorized_access': 'Data breach, privilege escalation',
            'can_injection': 'Vehicle control manipulation',
            'protocol_violation': 'Unexpected behavior',
        }
        
        return impacts.get(vuln_type, 'Unknown impact')
    
    def _calculate_priority(
        self,
        score: float,
        exploitability: str,
        automotive_impact: str
    ) -> int:
        """Calculate remediation priority (1-5, 1 is most urgent)."""
        
        # Start with score-based priority
        if score >= 9.0:
            priority = 1
        elif score >= 7.0:
            priority = 2
        elif score >= 5.0:
            priority = 3
        elif score >= 3.0:
            priority = 4
        else:
            priority = 5
        
        # Adjust for high exploitability
        if exploitability == 'high' and priority > 1:
            priority -= 1
        
        # Adjust for high automotive impact
        if automotive_impact in ['ASIL-D', 'ASIL-C'] and priority > 1:
            priority -= 1
        
        return max(1, min(5, priority))
    
    def get_severity_label(self, score: float) -> str:
        """
        Get severity label for a score.
        
        Args:
            score: Numeric score 0-10
            
        Returns:
            Severity label
        """
        return self._score_to_severity(score)
    
    def assess_automotive_impact(self, vuln: Dict[str, Any]) -> str:
        """
        Assess automotive safety impact.
        
        Args:
            vuln: Vulnerability dictionary
            
        Returns:
            ASIL level string
        """
        return self._assess_automotive_impact(vuln)
    
    def prioritize_remediation(
        self,
        vulnerabilities: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Sort vulnerabilities by remediation priority.
        
        Args:
            vulnerabilities: List of vulnerability dictionaries
            
        Returns:
            Sorted list with priority information added
        """
        scored_vulns = []
        
        for vuln in vulnerabilities:
            result = self.calculate_score(vuln)
            
            # Add scoring results to vulnerability
            vuln['calculated_score'] = result.base_score
            vuln['calculated_severity'] = result.severity_label
            vuln['automotive_impact'] = result.automotive_impact
            vuln['priority'] = result.priority
            vuln['impact_description'] = result.impact
            
            scored_vulns.append(vuln)
        
        # Sort by priority (ascending) then by score (descending)
        return sorted(
            scored_vulns,
            key=lambda x: (x.get('priority', 5), -x.get('calculated_score', 0))
        )
    
    def generate_summary_stats(
        self,
        vulnerabilities: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Generate summary statistics for vulnerabilities.
        
        Args:
            vulnerabilities: List of vulnerability dictionaries
            
        Returns:
            Summary statistics dictionary
        """
        if not vulnerabilities:
            return {
                'total': 0,
                'by_severity': {},
                'by_priority': {},
                'by_automotive_impact': {},
                'average_score': 0.0,
            }
        
        stats = {
            'total': len(vulnerabilities),
            'by_severity': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'info': 0},
            'by_priority': {1: 0, 2: 0, 3: 0, 4: 0, 5: 0},
            'by_automotive_impact': {},
            'by_type': {},
            'total_score': 0.0,
        }
        
        for vuln in vulnerabilities:
            # Count by severity
            severity = vuln.get('calculated_severity') or vuln.get('severity', 'medium')
            stats['by_severity'][severity] = stats['by_severity'].get(severity, 0) + 1
            
            # Count by priority
            priority = vuln.get('priority', 3)
            stats['by_priority'][priority] = stats['by_priority'].get(priority, 0) + 1
            
            # Count by automotive impact
            impact = vuln.get('automotive_impact', 'QM')
            stats['by_automotive_impact'][impact] = \
                stats['by_automotive_impact'].get(impact, 0) + 1
            
            # Count by type
            vuln_type = vuln.get('type', 'unknown')
            stats['by_type'][vuln_type] = stats['by_type'].get(vuln_type, 0) + 1
            
            # Sum scores
            stats['total_score'] += vuln.get('calculated_score', 0)
        
        stats['average_score'] = round(stats['total_score'] / len(vulnerabilities), 1)
        del stats['total_score']
        
        return stats
